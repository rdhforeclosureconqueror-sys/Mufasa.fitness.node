<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Mufasa Coach – Live AI Workout</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <!-- TensorFlow + Pose Detection (UMD builds give us global `tf` and `posedetection`) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@4.18.0/dist/tf-core.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@4.18.0/dist/tf-converter.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.18.0/dist/tf-backend-webgl.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@3.0.0/dist/pose-detection.min.js"></script>

  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }

    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      background: #020617;
      color: #e5e7eb;
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: stretch;
      padding: 12px;
    }

    .app {
      width: 100%;
      max-width: 1200px;
      display: grid;
      grid-template-columns: minmax(0, 2fr) minmax(0, 1.2fr);
      gap: 16px;
    }

    @media (max-width: 900px) {
      .app {
        grid-template-columns: minmax(0, 1fr);
      }
    }

    .panel {
      background: #020617;
      border-radius: 16px;
      border: 1px solid #1f2937;
      padding: 16px;
      box-shadow: 0 18px 35px rgba(0,0,0,0.7);
    }

    h1 {
      font-size: 1.3rem;
      margin-bottom: 4px;
    }
    h2 {
      font-size: 1.1rem;
      margin-bottom: 4px;
    }
    .subtitle {
      font-size: 0.9rem;
      color: #9ca3af;
      margin-bottom: 12px;
    }

    .video-wrapper {
      position: relative;
      border-radius: 16px;
      overflow: hidden;
      background: radial-gradient(circle at top, #0ea5e9, #1e293b);
      min-height: 260px;
    }

    video {
      width: 100%;
      height: 100%;
      object-fit: cover;
      transform: scaleX(-1); /* mirror like a mirror */
    }

    canvas {
      position: absolute;
      left: 0;
      top: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
    }

    .chip-row {
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
      margin: 10px 0;
    }

    .chip {
      font-size: 0.75rem;
      padding: 4px 8px;
      border-radius: 999px;
      border: 1px solid #374151;
      background: rgba(15,23,42,0.8);
    }

    .controls {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-top: 10px;
    }

    button {
      border: none;
      border-radius: 9999px;
      padding: 8px 16px;
      font-size: 0.9rem;
      font-weight: 500;
      cursor: pointer;
      background: #22c55e;
      color: #022c22;
      transition: transform 0.05s ease, box-shadow 0.1s ease, background 0.1s ease;
    }

    button.secondary {
      background: #0f172a;
      color: #e5e7eb;
      border: 1px solid #334155;
    }

    button:active {
      transform: translateY(1px);
      box-shadow: 0 0 0;
    }

    button[disabled] {
      opacity: 0.5;
      cursor: default;
    }

    .status {
      margin-top: 8px;
      font-size: 0.8rem;
      color: #a5b4fc;
      min-height: 1em;
    }

    .log-box {
      margin-top: 10px;
      max-height: 240px;
      overflow-y: auto;
      font-size: 0.8rem;
      padding-right: 4px;
    }

    .log-entry {
      padding: 6px 8px;
      border-radius: 8px;
      background: #020617;
      border: 1px solid #111827;
      margin-bottom: 6px;
    }

    .log-entry.system {
      border-color: #4b5563;
      color: #9ca3af;
    }

    .log-entry.coach {
      border-color: #22c55e;
      color: #bbf7d0;
    }

    .log-entry.user {
      border-color: #38bdf8;
      color: #e0f2fe;
    }

    .field-label {
      font-size: 0.8rem;
      color: #9ca3af;
      margin-top: 8px;
      margin-bottom: 4px;
    }

    textarea, input[type="text"] {
      width: 100%;
      border-radius: 10px;
      border: 1px solid #374151;
      background: #020617;
      color: #e5e7eb;
      padding: 8px 10px;
      font-size: 0.85rem;
    }

    footer {
      margin-top: 10px;
      font-size: 0.75rem;
      color: #6b7280;
    }
  </style>
</head>
<body>
  <div class="app">
    <!-- LEFT: Live camera + pose detection -->
    <section class="panel">
      <h1>Mufasa Live Coach</h1>
      <p class="subtitle">Camera + pose tracking + real-time coaching hooks.</p>

      <div class="video-wrapper">
        <video id="camera" autoplay playsinline muted></video>
        <canvas id="overlay"></canvas>
      </div>

      <div class="chip-row">
        <div class="chip">Pose: <span id="poseStatus">idle</span></div>
        <div class="chip">Reps: <span id="repCount">0</span></div>
        <div class="chip">Depth: <span id="depthLabel">–</span></div>
      </div>

      <div class="controls">
        <button id="camBtn">Connect Camera</button>
        <button id="startBtn" class="secondary" disabled>Start Workout</button>
      </div>

      <div class="status" id="poseMsg"></div>
    </section>

    <!-- RIGHT: Brain chat + voice -->
    <section class="panel">
      <h2>Talk to the Coach</h2>
      <p class="subtitle">Ask questions + get spoken answers from the Mufasa brain.</p>

      <div class="field-label">Ask a question</div>
      <textarea id="question" rows="3" placeholder="Example: Give me a 3-exercise leg workout I can do at home with no equipment."></textarea>

      <div class="controls" style="margin-top:6px;">
        <button id="askBtn">Ask Coach</button>
        <button id="muteBtn" class="secondary">Mute voice</button>
      </div>

      <div class="status" id="brainStatus"></div>

      <div class="field-label">Conversation</div>
      <div class="log-box" id="log"></div>

      <footer>
        Brain: <code>https://mufasabrain.onrender.com/ask</code><br>
        This is an early prototype – camera runs fully in your browser.
      </footer>
    </section>
  </div>

  <script>
    // === CONFIG: backend URLs ===
    const BRAIN_URL = "https://mufasabrain.onrender.com/ask";

    // === Simple UI helpers ===
    const poseStatusEl = document.getElementById("poseStatus");
    const repCountEl = document.getElementById("repCount");
    const depthLabelEl = document.getElementById("depthLabel");
    const poseMsgEl = document.getElementById("poseMsg");

    const brainStatusEl = document.getElementById("brainStatus");
    const logEl = document.getElementById("log");

    const camBtn = document.getElementById("camBtn");
    const startBtn = document.getElementById("startBtn");
    const askBtn = document.getElementById("askBtn");
    const muteBtn = document.getElementById("muteBtn");
    const questionEl = document.getElementById("question");

    const videoEl = document.getElementById("camera");
    const canvasEl = document.getElementById("overlay");
    const ctx = canvasEl.getContext("2d");

    let detector = null;
    let running = false;
    let reps = 0;
    let voiceMuted = false;

    function addLog(type, text) {
      const div = document.createElement("div");
      div.className = "log-entry " + type;
      div.textContent = text;
      logEl.prepend(div);
    }

    function speak(text) {
      if (voiceMuted) return;
      if (!("speechSynthesis" in window)) return;
      const u = new SpeechSynthesisUtterance(text);
      u.rate = 1.0;
      u.pitch = 1.0;
      speechSynthesis.speak(u);
    }

    // === Pose detection init ===
    async function initDetector() {
      poseMsgEl.textContent = "Loading TensorFlow + pose-detection…";
      await tf.ready();
      detector = await posedetection.createDetector(
        posedetection.SupportedModels.MoveNet,
        {
          modelType: posedetection.movenet.modelType.SINGLEPOSE_LIGHTNING
        }
      );
      poseMsgEl.textContent = "Detector ready. Stand where I can see your full body.";
    }

    async function connectCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { width: 640, height: 480 },
          audio: false
        });
        videoEl.srcObject = stream;
        videoEl.onloadedmetadata = () => {
          videoEl.play();
          canvasEl.width = videoEl.videoWidth;
          canvasEl.height = videoEl.videoHeight;
        };
        poseStatusEl.textContent = "camera ready";
        camBtn.disabled = true;
        startBtn.disabled = false;

        if (!detector) {
          await initDetector();
        }
      } catch (err) {
        console.error(err);
        poseMsgEl.textContent = "Could not access camera: " + err.message;
      }
    }

    function estimateDepthFromPose(pose) {
      // VERY rough: use knee y-positions difference as placeholder.
      if (!pose || !pose.keypoints || pose.keypoints.length === 0) return 0;
      const hip = pose.keypoints.find(k => k.name === "left_hip" || k.name === "right_hip");
      const knee = pose.keypoints.find(k => k.name === "left_knee" || k.name === "right_knee");
      if (!hip || !knee || hip.score < 0.4 || knee.score < 0.4) return 0;
      const dy = knee.y - hip.y;
      // Normalize to simple score
      return Math.max(0, Math.min(1, dy / 160));
    }

    async function runPoseLoop() {
      if (!detector) return;
      running = true;
      reps = 0;
      repCountEl.textContent = "0";
      poseStatusEl.textContent = "tracking";

      let wasLow = false;

      speak("Workout begins in 3, 2, 1.");

      const loop = async () => {
        if (!running) return;

        const poses = await detector.estimatePoses(videoEl);
        ctx.clearRect(0, 0, canvasEl.width, canvasEl.height);

        if (poses && poses.length > 0) {
          const pose = poses[0];
          // Draw simple keypoints
          ctx.fillStyle = "#22c55e";
          for (const kp of pose.keypoints) {
            if (kp.score > 0.4) {
              ctx.beginPath();
              ctx.arc(kp.x, kp.y, 4, 0, Math.PI * 2);
              ctx.fill();
            }
          }

          const depth = estimateDepthFromPose(pose);
          depthLabelEl.textContent = depth.toFixed(2);

          const isLow = depth > 0.7;
          if (isLow && !wasLow) {
            // bottom of rep
            wasLow = true;
            poseMsgEl.textContent = "Nice depth – drive up!";
            speak("Good depth, drive up through your heels.");
          } else if (!isLow && wasLow) {
            // standing back up
            wasLow = false;
            reps++;
            repCountEl.textContent = String(reps);
          }
        } else {
          poseStatusEl.textContent = "no body detected";
          depthLabelEl.textContent = "–";
        }

        requestAnimationFrame(loop);
      };

      requestAnimationFrame(loop);
    }

    function stopWorkout() {
      running = false;
      poseStatusEl.textContent = "stopped";
      poseMsgEl.textContent = "Workout ended.";
      speak("Workout complete. Great work, Rashad.");
    }

    // === Brain call ===
    async function askCoach() {
      const q = questionEl.value.trim();
      if (!q) {
        alert("Type a question first.");
        return;
      }

      brainStatusEl.textContent = "Talking to brain…";
      addLog("user", q);

      try {
        const res = await fetch(BRAIN_URL, {
          method: "POST",
          headers: {
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            question: q,
            domain: "fitness",
            user_id: "rashad",
            session_id: "browser-demo"
          })
        });

        if (!res.ok) {
          const text = await res.text();
          console.error("Brain error", res.status, text);
          brainStatusEl.textContent = "Brain error: " + res.status;
          addLog("system", "Brain error: " + res.status);
          return;
        }

        const data = await res.json();
        const answer = data.answer || "(no answer field)";

        addLog("coach", answer);
        brainStatusEl.textContent = "Coach answered.";
        speak(answer);
      } catch (err) {
        console.error(err);
        brainStatusEl.textContent = "Network error talking to brain.";
        addLog("system", "Network error talking to brain.");
      }
    }
<script>
window.addEventListener("load", () => {
  console.log("TensorFlow loaded:", typeof tf !== "undefined");
  console.log("PoseDetection loaded:", typeof posedetection !== "undefined");
});
</script>

    // === Wire up buttons ===
    camBtn.onclick = connectCamera;
    startBtn.onclick = () => {
      if (!running) {
        startBtn.textContent = "Stop Workout";
        startBtn.classList.remove("secondary");
        startBtn.style.background = "#ef4444";
        runPoseLoop();
      } else {
        startBtn.textContent = "Start Workout";
        startBtn.classList.add("secondary");
        startBtn.style.background = "";
        stopWorkout();
      }
    };

    askBtn.onclick = askCoach;

    muteBtn.onclick = () => {
      voiceMuted = !voiceMuted;
      muteBtn.textContent = voiceMuted ? "Unmute voice" : "Mute voice";
    };

    // Initial log
    addLog("system", "Mufasa Coach loaded. Connect your camera and ask the coach anything.");
  </script>
</body>
</html>
